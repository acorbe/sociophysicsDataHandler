{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/..')\n",
    "from sociophysicsDataHandler import spdh\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import requests\n",
    "import pyarrow.parquet as pq\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler = spdh.SociophysicsDataHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = '03'\n",
    "files = glob.glob(rf'C:\\Users\\caspouw\\Downloads\\EHV\\04\\01\\EHV\\Perron2.1\\2*')\n",
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(rf'C:\\Users\\caspouw\\Downloads\\EHV\\04\\01\\EHV\\Perron*\\2*')\n",
    "def convert_file_names(file):\n",
    "#     print(f\"--- Start file {file}\")\n",
    "    station = file.split('\\\\')[-3]\n",
    "    file_name = file.split('\\\\')[-1]\n",
    "    platform = file.split('\\\\')[-2]\n",
    "#     platform_no = platform.split('.')[-1a\n",
    "    date = file.split('\\\\')[-1].split('_')[0]\n",
    "    if station.lower() == \"ut\":\n",
    "        pf_indication = platform[-3]\n",
    "        platform_name = 'Perron'\n",
    "        platform_name2 = platform_name\n",
    "    else:\n",
    "        pf_indication = platform[-3:]\n",
    "        platform_name = 'Platform'\n",
    "        platform_name2 = platform_name.lower()\n",
    "    return f\"/ProRail_USE_LL_data/{station.lower()}/{platform_name2}{pf_indication}/{date[:8]}/{station}_{platform_name}{pf_indication}_{file_name}\"\n",
    "\n",
    "# for file in files:\n",
    "#     print(convert_file_names(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list = []\n",
    "for station in ['EHV']:\n",
    "# for station in ['UT']:\n",
    "    for day in np.arange(26,31):\n",
    "        print(f\"Start day {day:02} station {station}\")\n",
    "#         files = glob.glob(rf'C:\\Users\\caspouw\\Downloads\\{month}\\{day:02}\\{station}\\Perron*\\*')\n",
    "        files = glob.glob(rf'C:\\Users\\caspouw\\Downloads\\{station}\\04\\{day:02}\\{station}\\Perron*\\*')\n",
    "        for file in files:\n",
    "            converted_file_name = convert_file_names(file)\n",
    "            try:\n",
    "#                 print('try')\n",
    "                data_handler._SociophysicsDataHandler__oc_client.put_file(converted_file_name, \n",
    "                                                                          file)    \n",
    "            except Exception as e:\n",
    "#                 print('except')\n",
    "#                 logging.error('Error at %s', 'division', exc_info=e)\n",
    "#                 error_list.append(e)\n",
    "                folder_name_parts = converted_file_name.split('/')\n",
    "                if station == \"ASDZ\":\n",
    "                    folder_name = f'/ProRail_USE_LL_data/{folder_name_parts[2]}/{folder_name_parts[3].lower()}/{folder_name_parts[4]}/'\n",
    "                elif station == \"UT\":\n",
    "                    folder_name = f'/ProRail_USE_LL_data/{folder_name_parts[2]}/{folder_name_parts[3]}/{folder_name_parts[4]}/'\n",
    "                elif station == \"EHV\":\n",
    "                    folder_name = f'/ProRail_USE_LL_data/{folder_name_parts[2]}/{folder_name_parts[3]}/{folder_name_parts[4]}/'\n",
    "                data_handler._SociophysicsDataHandler__oc_client.mkdir(folder_name)\n",
    "                print(f\"Made folder {folder_name}\")\n",
    "                data_handler._SociophysicsDataHandler__oc_client.put_file(converted_file_name, file)    \n",
    "        print(f\"Finished day {day:02}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "    complete_list = pd.DataFrame()\n",
    "    folders = data_handler.list_files('/ProRail_USE_LL_data/').name.unique()\n",
    "    stations = [s for s in folders if \"_\" not in s]\n",
    "#     np.delete(stations, np.where(areas == 'eindhoven'))\n",
    "    for station in stations:\n",
    "        areas = data_handler.list_files(f'/ProRail_USE_LL_data/{station}/').name.unique()\n",
    "        areas = [s for s in areas if \".pdf\" not in s]\n",
    "#         np.delete(areas, np.where(areas == 'eindhoven'))\n",
    "        for area in areas:\n",
    "            file_list = data_handler.list_files(f'/ProRail_USE_LL_data/{station}/{area}/')\n",
    "            file_list['last_modified'] = file_list.attributes.apply(lambda x: list(x.values())[0])\n",
    "            file_list = file_list[['name', 'last_modified']].copy()\n",
    "            file_list.columns = ['date', 'last_modified']\n",
    "            file_list['station'] = station\n",
    "            file_list['area'] = area\n",
    "            complete_list = complete_list.append(file_list)\n",
    "\n",
    "    complete_list['last_modified'] = complete_list.last_modified.apply(lambda x: pd.to_datetime(x))\n",
    "    complete_list = complete_list.sort_values('last_modified', ascending = False)\n",
    "    complete_list[['station', 'area', 'date', 'last_modified']].to_csv('upload_log.csv')\n",
    "    data_handler._SociophysicsDataHandler__oc_client.put_file(f\"/ProRail_USE_LL_data/\", \"upload_log.csv\")\n",
    "    print('Log uploaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/ProRail_USE_LL_data/ehv/platform2.1/20210330/'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'ProRail_USE_LL_data',\n",
       " 'ehv',\n",
       " 'platform2.1',\n",
       " '20210330',\n",
       " 'EHV_Platform2.1_2021033008_trajectorie.parquet']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_name_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/ProRail_USE_LL_data/ehv/platform2.1/20210330/EHV_Platform2.1_2021033008_trajectorie.parquet'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'folder_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-899954c6215d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfolder_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'folder_name' is not defined"
     ]
    }
   ],
   "source": [
    "folder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crowdflow",
   "language": "python",
   "name": "crowdflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
